{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9503f8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_trained_model = 'resnet101'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b835fe",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef1aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import timm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e60f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/AD_Heewon'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "509de19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 작업경로 확인\n",
    "#path = '/home/nextgen/Downloads/Heewon_download/data'\n",
    "\n",
    "#os.chdir(path)\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea53556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_png = sorted(glob('open/train/*.png'))\n",
    "test_png = sorted(glob('open/test/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63109cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = pd.read_csv(\"open/train_df.csv\")\n",
    "\n",
    "train_labels = train_y[\"label\"]\n",
    "\n",
    "label_unique = sorted(np.unique(train_labels))\n",
    "label_unique = {key:value for key,value in zip(label_unique, range(len(label_unique)))}\n",
    "\n",
    "train_labels = [label_unique[k] for k in train_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "045ff68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 호영's code\n",
    "\n",
    "index_good = train_y[train_y['state'] == 'good'].index\n",
    "index_bad = [i for i in list(np.arange(len(train_labels))) if i not in list(index_good)]\n",
    "\n",
    "for i in index_bad:\n",
    "    train_labels.append(train_labels[i]) #품질 나쁜 리스트 추가\n",
    "    train_labels.append(train_labels[i]) \n",
    "    train_labels.append(train_labels[i]) \n",
    "    train_labels.append(train_labels[i]) \n",
    "    train_labels.append(train_labels[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6226f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_load(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (512, 512))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce021a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4277/4277 [02:59<00:00, 23.81it/s]\n",
      "100%|██████████| 2154/2154 [01:20<00:00, 26.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_imgs = [img_load(m) for m in tqdm(train_png)]\n",
    "test_imgs = [img_load(n) for n in tqdm(test_png)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07b107bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 648/648 [00:26<00:00, 24.33it/s]\n"
     ]
    }
   ],
   "source": [
    "#호영's code\n",
    "height, width = train_imgs[0].shape[:2]\n",
    "\n",
    "img90 = cv2.getRotationMatrix2D((height/2, width/2), 90 ,1)\n",
    "img180 = cv2.getRotationMatrix2D((height/2, width/2), 180 ,1)\n",
    "img270 = cv2.getRotationMatrix2D((height/2, width/2), 270 ,1)\n",
    "\n",
    "train_png_bad = []\n",
    "for i in index_bad:\n",
    "    train_png_bad.append(train_png[i]) #품질 나쁜 리스트의 사진을 추가\n",
    "    \n",
    "train_imgs_bad = []\n",
    "for j in [90,180,270]:\n",
    "    for i in tqdm(train_png_bad):\n",
    "        img = img_load(i)\n",
    "        train_imgs_bad.append(cv2.warpAffine(img, globals()['img'+str(j)], (width, height)))\n",
    "\n",
    "train_imgs.extend(train_imgs_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5799d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#호영's code\n",
    "\n",
    "height, width = train_imgs[0].shape[:2]\n",
    "\n",
    "pts1 = np.float32([[0,0],[width-1,0],[0,height-1]])\n",
    "pts2 = np.float32([[0,0],[width-25,25],[25, height-25]])\n",
    "\n",
    "train_png_bad = []\n",
    "for i in index_bad:\n",
    "    train_png_bad.append(train_png[i]) #품질 나쁜 리스트의 사진을 추가\n",
    "    \n",
    "train_imgs_bad = []\n",
    "for i in tqdm(train_png_bad):\n",
    "    mat = cv2.getAffineTransform(pts1,pts2)\n",
    "    img = img_load(i)\n",
    "    train_imgs_bad.append(cv2.warpAffine(img, mat, None)) #행렬 변환을 통한 그림 생성\n",
    "\n",
    "train_imgs.extend(train_imgs_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95243657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#호영's code\n",
    "\n",
    "height, width = train_imgs[0].shape[:2]\n",
    "\n",
    "pts1 = np.float32([[0,0],[width-1,0],[0,height-1]])\n",
    "pts2 = np.float32([[0,0],[width+25,-25],[-25, height+25]])\n",
    "\n",
    "train_png_bad = []\n",
    "for i in index_bad:\n",
    "    train_png_bad.append(train_png[i]) #품질 나쁜 리스트의 사진을 추가\n",
    "    \n",
    "train_imgs_bad = []\n",
    "for i in tqdm(train_png_bad):\n",
    "    mat = cv2.getAffineTransform(pts1,pts2)\n",
    "    img = img_load(i)\n",
    "    train_imgs_bad.append(cv2.warpAffine(img, mat, None)) #행렬 변환을 통한 그림 생성\n",
    "\n",
    "train_imgs.extend(train_imgs_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d6aadf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_dataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, mode='train'):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.mode=mode\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.img_paths[idx]\n",
    "        if self.mode=='train':\n",
    "            augmentation = random.randint(0,2)\n",
    "            if augmentation==1:\n",
    "                img = img[::-1].copy()\n",
    "            elif augmentation==2:\n",
    "                img = img[:,::-1].copy()\n",
    "        img = transforms.ToTensor()(img)\n",
    "        if self.mode=='test':\n",
    "            pass\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "    \n",
    "    \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.model = timm.create_model(pre_trained_model, pretrained=True, num_classes=88)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4fb7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 50\n",
    "\n",
    "# Train\n",
    "train_dataset = Custom_dataset(np.array(train_imgs), np.array(train_labels), mode='train')\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "# Test\n",
    "test_dataset = Custom_dataset(np.array(test_imgs), np.array([\"tmp\"]*len(test_imgs)), mode='test')\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9b3541",
   "metadata": {},
   "source": [
    "### 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5050a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_function(real, pred):\n",
    "    score = f1_score(real, pred, average=\"macro\")\n",
    "    return score\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "# best=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aeff6038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/50    time : 78s/3826s\n",
      "TRAIN    loss : 1.71524    f1 : 0.14959\n",
      "epoch : 2/50    time : 80s/3818s\n",
      "TRAIN    loss : 0.90131    f1 : 0.27237\n",
      "epoch : 3/50    time : 79s/3707s\n",
      "TRAIN    loss : 0.75988    f1 : 0.34178\n",
      "epoch : 4/50    time : 79s/3642s\n",
      "TRAIN    loss : 0.64236    f1 : 0.44179\n",
      "epoch : 5/50    time : 80s/3594s\n",
      "TRAIN    loss : 0.53525    f1 : 0.53620\n",
      "epoch : 6/50    time : 78s/3420s\n",
      "TRAIN    loss : 0.47765    f1 : 0.59587\n",
      "epoch : 7/50    time : 79s/3411s\n",
      "TRAIN    loss : 0.42331    f1 : 0.62237\n",
      "epoch : 8/50    time : 79s/3314s\n",
      "TRAIN    loss : 0.37132    f1 : 0.68796\n",
      "epoch : 9/50    time : 79s/3223s\n",
      "TRAIN    loss : 0.35822    f1 : 0.70603\n",
      "epoch : 10/50    time : 78s/3121s\n",
      "TRAIN    loss : 0.29136    f1 : 0.74105\n",
      "epoch : 11/50    time : 79s/3068s\n",
      "TRAIN    loss : 0.23728    f1 : 0.79238\n",
      "epoch : 12/50    time : 80s/3042s\n",
      "TRAIN    loss : 0.22738    f1 : 0.81514\n",
      "epoch : 13/50    time : 80s/2959s\n",
      "TRAIN    loss : 0.22241    f1 : 0.82077\n",
      "epoch : 14/50    time : 79s/2854s\n",
      "TRAIN    loss : 0.18973    f1 : 0.85663\n",
      "epoch : 15/50    time : 79s/2756s\n",
      "TRAIN    loss : 0.18664    f1 : 0.84796\n",
      "epoch : 16/50    time : 78s/2651s\n",
      "TRAIN    loss : 0.16018    f1 : 0.87278\n",
      "epoch : 17/50    time : 79s/2614s\n",
      "TRAIN    loss : 0.13440    f1 : 0.88189\n",
      "epoch : 18/50    time : 80s/2546s\n",
      "TRAIN    loss : 0.15504    f1 : 0.89611\n",
      "epoch : 19/50    time : 80s/2468s\n",
      "TRAIN    loss : 0.12812    f1 : 0.90041\n",
      "epoch : 20/50    time : 78s/2352s\n",
      "TRAIN    loss : 0.10228    f1 : 0.93586\n",
      "epoch : 21/50    time : 78s/2273s\n",
      "TRAIN    loss : 0.12789    f1 : 0.90678\n",
      "epoch : 22/50    time : 80s/2237s\n",
      "TRAIN    loss : 0.09855    f1 : 0.92570\n",
      "epoch : 23/50    time : 77s/2088s\n",
      "TRAIN    loss : 0.12229    f1 : 0.91904\n",
      "epoch : 24/50    time : 79s/2056s\n",
      "TRAIN    loss : 0.09518    f1 : 0.93534\n",
      "epoch : 25/50    time : 78s/1946s\n",
      "TRAIN    loss : 0.09460    f1 : 0.93693\n",
      "epoch : 26/50    time : 78s/1872s\n",
      "TRAIN    loss : 0.08336    f1 : 0.93632\n",
      "epoch : 27/50    time : 78s/1789s\n",
      "TRAIN    loss : 0.09295    f1 : 0.94022\n",
      "epoch : 28/50    time : 79s/1737s\n",
      "TRAIN    loss : 0.09073    f1 : 0.94075\n",
      "epoch : 29/50    time : 78s/1644s\n",
      "TRAIN    loss : 0.08351    f1 : 0.94913\n",
      "epoch : 30/50    time : 79s/1574s\n",
      "TRAIN    loss : 0.06080    f1 : 0.96240\n",
      "epoch : 31/50    time : 79s/1509s\n",
      "TRAIN    loss : 0.10143    f1 : 0.92960\n",
      "epoch : 32/50    time : 79s/1413s\n",
      "TRAIN    loss : 0.08546    f1 : 0.94476\n",
      "epoch : 33/50    time : 78s/1331s\n",
      "TRAIN    loss : 0.06607    f1 : 0.95437\n",
      "epoch : 34/50    time : 79s/1268s\n",
      "TRAIN    loss : 0.06976    f1 : 0.95579\n",
      "epoch : 35/50    time : 79s/1184s\n",
      "TRAIN    loss : 0.05196    f1 : 0.96401\n",
      "epoch : 36/50    time : 79s/1106s\n",
      "TRAIN    loss : 0.07133    f1 : 0.94529\n",
      "epoch : 37/50    time : 78s/1015s\n",
      "TRAIN    loss : 0.04884    f1 : 0.95983\n",
      "epoch : 38/50    time : 78s/931s\n",
      "TRAIN    loss : 0.04714    f1 : 0.96555\n",
      "epoch : 39/50    time : 79s/868s\n",
      "TRAIN    loss : 0.03167    f1 : 0.98238\n",
      "epoch : 40/50    time : 78s/784s\n",
      "TRAIN    loss : 0.04853    f1 : 0.96586\n",
      "epoch : 41/50    time : 78s/702s\n",
      "TRAIN    loss : 0.07244    f1 : 0.96017\n",
      "epoch : 42/50    time : 78s/627s\n",
      "TRAIN    loss : 0.06603    f1 : 0.96151\n",
      "epoch : 43/50    time : 78s/548s\n",
      "TRAIN    loss : 0.05019    f1 : 0.96828\n",
      "epoch : 44/50    time : 78s/469s\n",
      "TRAIN    loss : 0.04790    f1 : 0.96186\n",
      "epoch : 45/50    time : 79s/397s\n",
      "TRAIN    loss : 0.03770    f1 : 0.97981\n",
      "epoch : 46/50    time : 79s/316s\n",
      "TRAIN    loss : 0.06251    f1 : 0.96339\n",
      "epoch : 47/50    time : 78s/234s\n",
      "TRAIN    loss : 0.05919    f1 : 0.96357\n",
      "epoch : 48/50    time : 80s/161s\n",
      "TRAIN    loss : 0.03320    f1 : 0.97902\n",
      "epoch : 49/50    time : 78s/78s\n",
      "TRAIN    loss : 0.04481    f1 : 0.96920\n",
      "epoch : 50/50    time : 79s/0s\n",
      "TRAIN    loss : 0.02391    f1 : 0.98221\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    start=time.time()\n",
    "    train_loss = 0\n",
    "    train_pred=[]\n",
    "    train_y=[]\n",
    "    model.train()\n",
    "    for batch in (train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.tensor(batch[0], dtype=torch.float32, device=device)\n",
    "        y = torch.tensor(batch[1], dtype=torch.long, device=device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()/len(train_loader)\n",
    "        train_pred += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "        train_y += y.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    \n",
    "    train_f1 = score_function(train_y, train_pred)\n",
    "\n",
    "    TIME = time.time() - start\n",
    "    print(f'epoch : {epoch+1}/{epochs}    time : {TIME:.0f}s/{TIME*(epochs-epoch-1):.0f}s')\n",
    "    print(f'TRAIN    loss : {train_loss:.5f}    f1 : {train_f1:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740cceb",
   "metadata": {},
   "source": [
    "### 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9452744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "f_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in (test_loader):\n",
    "        x = torch.tensor(batch[0], dtype = torch.float32, device = device)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            pred = model(x)\n",
    "        f_pred.extend(pred.argmax(1).detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1db9382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {val:key for key, val in label_unique.items()}\n",
    "\n",
    "f_result = [label_decoder[result] for result in f_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371c1822",
   "metadata": {},
   "source": [
    "### 제출물 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6ffd7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tile-glue_strip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>transistor-misplaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tile-gray_stroke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>2149</td>\n",
       "      <td>tile-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150</th>\n",
       "      <td>2150</td>\n",
       "      <td>screw-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151</th>\n",
       "      <td>2151</td>\n",
       "      <td>grid-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2152</th>\n",
       "      <td>2152</td>\n",
       "      <td>cable-good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>2153</td>\n",
       "      <td>zipper-good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2154 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                 label\n",
       "0         0       tile-glue_strip\n",
       "1         1             grid-good\n",
       "2         2  transistor-misplaced\n",
       "3         3      tile-gray_stroke\n",
       "4         4             tile-good\n",
       "...     ...                   ...\n",
       "2149   2149             tile-good\n",
       "2150   2150            screw-good\n",
       "2151   2151             grid-good\n",
       "2152   2152            cable-good\n",
       "2153   2153           zipper-good\n",
       "\n",
       "[2154 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"open/sample_submission.csv\")\n",
    "\n",
    "submission[\"label\"] = f_result\n",
    "\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "782b23d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/AD_Heewon'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7af3ed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"open/result/{}(batch={}, epoch={}).csv\".format(pre_trained_model, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2000bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"open/resnet101(batch=16, epoch=50).csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
